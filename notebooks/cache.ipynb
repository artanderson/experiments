{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Augmenting-Aerospike-with-Local-Cache¶\" data-toc-modified-id=\"Augmenting-Aerospike-with-Local-Cache¶-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Augmenting Aerospike with Local Cache¶</a></span><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Prerequisites\" data-toc-modified-id=\"Prerequisites-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Prerequisites</a></span></li><li><span><a href=\"#Initialization\" data-toc-modified-id=\"Initialization-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Initialization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Ensure-database-is-running\" data-toc-modified-id=\"Ensure-database-is-running-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Ensure database is running</a></span></li><li><span><a href=\"#Connect-to-database.\" data-toc-modified-id=\"Connect-to-database.-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Connect to database.</a></span></li><li><span><a href=\"#Populate-database-with-test-data.\" data-toc-modified-id=\"Populate-database-with-test-data.-1.3.3\"><span class=\"toc-item-num\">1.3.3&nbsp;&nbsp;</span>Populate database with test data.</a></span></li></ul></li></ul></li><li><span><a href=\"#Local-Cache\" data-toc-modified-id=\"Local-Cache-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Local Cache</a></span><ul class=\"toc-item\"><li><span><a href=\"#Simple-Interface\" data-toc-modified-id=\"Simple-Interface-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Simple Interface</a></span><ul class=\"toc-item\"><li><span><a href=\"#Eviction-Alternatives\" data-toc-modified-id=\"Eviction-Alternatives-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Eviction Alternatives</a></span></li><li><span><a href=\"#Working-with-Aerospike-TTL-Based-Eviction\" data-toc-modified-id=\"Working-with-Aerospike-TTL-Based-Eviction-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Working with Aerospike TTL Based Eviction</a></span></li></ul></li><li><span><a href=\"#Comparing-Performance\" data-toc-modified-id=\"Comparing-Performance-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Comparing Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#Benefits-of-a-local-cache\" data-toc-modified-id=\"Benefits-of-a-local-cache-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Benefits of a local cache</a></span></li></ul></li></ul></li><li><span><a href=\"#Cache-Performance\" data-toc-modified-id=\"Cache-Performance-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Cache Performance</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Model\" data-toc-modified-id=\"The-Model-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>The Model</a></span></li><li><span><a href=\"#Single-Cache\" data-toc-modified-id=\"Single-Cache-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Single Cache</a></span></li><li><span><a href=\"#Dual-Cache\" data-toc-modified-id=\"Dual-Cache-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Dual Cache</a></span></li></ul></li><li><span><a href=\"#Takeaways-and-Conclusion\" data-toc-modified-id=\"Takeaways-and-Conclusion-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Takeaways and Conclusion</a></span></li><li><span><a href=\"#Clean-up\" data-toc-modified-id=\"Clean-up-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Clean up</a></span></li><li><span><a href=\"#Further-Exploration-and-Resources\" data-toc-modified-id=\"Further-Exploration-and-Resources-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Further Exploration and Resources</a></span><ul class=\"toc-item\"><li><span><a href=\"#Next-steps\" data-toc-modified-id=\"Next-steps-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Next steps</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting Aerospike with Local Cache¶\n",
    "This notebook describes the pattern where a local cache is used in front of the Aerospike database. It shows with a simple model how a local cache can enhance performance for various hit ratio and cache speed scenarios.\n",
    "\n",
    "This notebook requires Aerospike datbase running on localhost and that python and the Aerospike python client have been installed (`pip install aerospike`). Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) for additional details and the docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Caches are ubiquitious. Aerospike is commonly and effectively deployed as a cache in front of a backend database that is remote, slow, and/or limited in throughput. This notebook illustrates use of a local cache that sits in front of the Aerospike database on the client machine. The pattern is applicable for a standalone Aerospike database as well as when Aerospike itself is used as a cache.\n",
    "\n",
    "A cache provides faster access by keeping the data closer to where it is needed. Examples of caches that are integral part of the computing infrastructure include L1, L2, memory, application specific server caches, and application specific client caches. Cache libraries, external caching servers, and distributed cache infrastructure are deployed for specific caching needs and solutions. Aerospike is designed for fast, reliable, consitent, and cost-effective access across the globally distributed data infrastructure.\n",
    "\n",
    "This notebook illustrates a simple API for a local cache in front of the Aerospike database.\n",
    "\n",
    "The notebook is divided in two parts:\n",
    "1. Part 1 (Section 2) illustrates a simple API for a local cache that front-ends Aerospike database.\n",
    "1. Part 2 (Section 3) uses a simple model to show the performance impact of a cache in various scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "This tutorial assumes familiarity with the following topics:\n",
    "\n",
    "- Familiarlity with Aerospike and API. See [Hello World](hello_world.ipynb)\n",
    "- Basic CRUD operations. See [Aerospike Basic Operations](basic_operations.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure database is running\n",
    "This notebook requires that Aerospike datbase is running. \n",
    "[Include the right code cell for Java or Python from the two cells below.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T18:28:57.038395Z",
     "start_time": "2021-01-12T18:28:56.755437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerospike database is running!\r\n"
     ]
    }
   ],
   "source": [
    "!asd >& /dev/null\n",
    "!pgrep -x asd >/dev/null && echo \"Aerospike database is running!\" || echo \"**Aerospike database is not running!**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to database.\n",
    "We need a client connected to the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:51.190060Z",
     "start_time": "2020-12-29T20:48:51.110597Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client successfully connected to the database.\n"
     ]
    }
   ],
   "source": [
    "# import the module\n",
    "from __future__ import print_function\n",
    "import aerospike\n",
    "\n",
    "# Configure the client\n",
    "config = {\n",
    "  'hosts': [ ('127.0.0.1', 3000) ],\n",
    "  'policy' : {'key': aerospike.POLICY_KEY_SEND}\n",
    "}\n",
    "\n",
    "# Create a client and connect it to the cluster\n",
    "try:\n",
    "  client = aerospike.client(config).connect()\n",
    "except:\n",
    "  import sys\n",
    "  print(\"failed to connect to the cluster with\", config['hosts'])\n",
    "  sys.exit(1)\n",
    "print('Client successfully connected to the database.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate database with test data.\n",
    "The following code populates the test data in set \"local-cache-tutorial\" in namespace \"test\". The data consists of a 10000 records with user keys 1-10000 and bins populated with random data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:48:52.195181Z",
     "start_time": "2020-12-29T20:48:52.189787Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n"
     ]
    }
   ],
   "source": [
    "namespace = 'test'\n",
    "tutorial_set = 'local_cache_tutorial'\n",
    "max_data_size = 10000\n",
    "# Records are addressable via a tuple of (namespace, set, key)\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "try:\n",
    "    for i in range(max_data_size):\n",
    "      # Write the records\n",
    "      client.put((namespace, tutorial_set, 'id-'+str(i+1)), \n",
    "                 { 'age': random.randint(20,81),\n",
    "                   'birth_month': random.choice(['Jan','Feb','Mar','Apr','May','Jun',\n",
    "                                               'Jul','Aug','Sep','Oct','Nov','Dec']),\n",
    "                   'gender': random.choice(['M', 'F']),\n",
    "                   'favorite_colors': random.sample(['red','orange','yellow','green',\n",
    "                                                   'blue','violet','black','white','grey'], k=3) } )\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"error: {0}\".format(e), file=sys.stderr)\n",
    "\n",
    "print('Test data populated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Cache\n",
    "\n",
    "Here we will illustrate how a local cache can be placed in front of the Aerospike database. Aerospike provides average access time of a millisecond or less for 99%+ requests. A local cache has greater speed advantage - 10-100 times greater - since a cache hit can be in 1-10 microsecond range.\n",
    "\n",
    "First, let us define the API for the local cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache Interface\n",
    "The cache consists of cache entries with the following key operations:\n",
    "- get(key)\n",
    "    - Get from cache if available and TTL not expired, else retrieve from the database and add to the cache.\n",
    "- update(key, data)\n",
    "    - Update the database by replacing the current record, and also add or replace the cache entry.\n",
    "- add(key, entry)\n",
    "    - If the cache is full, evict appropriate entry and add the cache entry.\n",
    "\n",
    "### Cache Eviction\n",
    "A local cache can be implemented with TTL based garbage collection. \n",
    "\n",
    "An alternative implementation can maintain a Least-Recently-Used (LRU) list. When the cache is full, the LRU entry is removed to make room for a new entry. LRU can be implemented by maintaining a doubly linked list of cache entries - the classes Cache and CacheEntry allude to the core data structure elements for LRU, but the logic to manage the doubly linked list (which should be straightforward) is not provided here.\n",
    "\n",
    "A simplistic implementation we have chosen here for illustrative purpose selects a random entry for eviction. A \"random\" replacement uses dict.popitem(), although better randomized eviction is possible with dict implementations like [randomdict](https://github.com/robtandy/randomdict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T17:05:39.701891Z",
     "start_time": "2021-01-12T17:05:39.687304Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "DEFAULT_TTL = 3600\n",
    "\n",
    "class CacheEntry:\n",
    "    _key = None\n",
    "    _ttl = 0\n",
    "    _data = None\n",
    "    # LRU not implemented\n",
    "    # _lru_prev = None\n",
    "    # _lru_next = None\n",
    "    \n",
    "    def __init__(self, key, ttl, data):\n",
    "        self._key = key\n",
    "        self._ttl = ttl\n",
    "        self._data = data.copy()\n",
    "        return\n",
    "        \n",
    "    \n",
    "class LocalCache:\n",
    "    _cache = {}   # dict of key->cache_entry\n",
    "    _max_size = 0\n",
    "    # LRU not implemented\n",
    "    # _lru_head = None\n",
    "    # _lru_tail = None\n",
    "\n",
    "    def __init__(self, max_size):\n",
    "        self._max_size = max_size\n",
    "        return\n",
    "\n",
    "    def get(self, key):\n",
    "        entry = self._cache.get(key)\n",
    "        if entry is None or entry._ttl < time.time():\n",
    "            #print(\"a cache miss\", key[2])\n",
    "            # get it from aerospike database\n",
    "            _, meta, bins = client.get(key)\n",
    "            if meta is None:\n",
    "                #print(\"entry expired at origin\", key[2])\n",
    "                if entry:\n",
    "                    self._cache.pop(key)\n",
    "                return None\n",
    "            if entry: # in cache, replace\n",
    "                entry._ttl = time.time()+meta['ttl']\n",
    "                entry._data = bins\n",
    "            else: # not in cache, add\n",
    "                entry = CacheEntry(key, time.time()+meta['ttl'], bins)\n",
    "                self.add(key, entry)\n",
    "        #else:\n",
    "            #print(\"a cache hit\", key[2])\n",
    "        return entry._data.copy()\n",
    "\n",
    "    def add(self, key, entry):\n",
    "        if len(self._cache) == self._max_size:\n",
    "            #print(\"cache full, evicting\")\n",
    "            _ = self._cache.popitem() # remove a \"random\" entry\n",
    "        self._cache[key] = entry\n",
    "        #print(\"added entry\", key[2])\n",
    "        return\n",
    "\n",
    "    def update(self, key, data):\n",
    "        # update aerospike database and extend TTL\n",
    "        meta = {'ttl': DEFAULT_TTL}\n",
    "        policy = {'exists': aerospike.POLICY_EXISTS_REPLACE}\n",
    "        try:\n",
    "            _, meta, _ = client.operate(key, data, meta=meta, policy=policy)\n",
    "        except:\n",
    "              print('failed to udpdate database')\n",
    "              raise\n",
    "        entry = self._cache.get(key)\n",
    "        if entry is None:\n",
    "            entry = CacheEntry(key, time.time()+DEFAULT_TTL, data)\n",
    "            self.add(key, entry)\n",
    "        else:\n",
    "            entry._ttl = time.time()+DEFAULT_TTL\n",
    "            entry._data = rec.copy()\n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with Aerospike TTL Based Eviction\n",
    "\n",
    "Aerospike has TTL based eviction that provides alternatives like: \n",
    "1. No eviction or the record is permanent, \n",
    "1. At record creation a specific TTL is set, \n",
    "1. TTL may be updated any time. \n",
    "\n",
    "Since the TTL can change at origin while the record resides in the local cache, the cache will sync up with the origin on TTL at the time of caching. This is no different from when the record is deleted at the origin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Performance\n",
    "How does a local cache aid performance of Aerospike database? It depends on two key factors. \n",
    "1. Cache hit ratio that combines factors like the cache size, invalidation (update) rate, and access pattern. \n",
    "1. Latency ratio or the ratio of Aerospike database access latency and local cache access latency. Essentially it is the speedup that a cache provides when there is a cache hit over a cache miss.\n",
    "\n",
    "Below we run a simple test and compare execution times without cache and with cache. You can experiment with different values of data_size and cache_size to adjust the hit ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time without cache:  1.924s\n",
      "Execution time with cache:  1.515s\n",
      "Speedup with cache:   27.0%\n"
     ]
    }
   ],
   "source": [
    "data_size = 5000\n",
    "cache_size = 2000\n",
    "num_requests = 10000\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(num_requests):\n",
    "    user_key = 'id-' + str(random.randint(1, data_size))\n",
    "    key = (namespace, tutorial_set, user_key)\n",
    "    _ = client.get(key)\n",
    "time_without_cache = time.time() - start_time\n",
    "print('Execution time without cache: ', '%5.3fs'%time_without_cache)\n",
    "\n",
    "start_time = time.time()\n",
    "cache = LocalCache(cache_size)\n",
    "for i in range(num_requests):\n",
    "    user_key = 'id-' + str(random.randint(1, data_size))\n",
    "    key = (namespace, tutorial_set, user_key)\n",
    "    _ = cache.get(key)\n",
    "time_with_cache = time.time() - start_time\n",
    "print('Execution time with cache: ', '%5.3fs'%time_with_cache)\n",
    "\n",
    "print('Speedup with cache: ', '%5.1f%%'%((time_without_cache/time_with_cache - 1) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benefits of a local cache\n",
    "\n",
    "A local cache is beneficial in the following situations, with greater impact as either or both of hit ratio and latency ratio increase.\n",
    "- If Aerospike is used as a database and not a cache for another database. \n",
    "- In cases where Aerospike is used as a cache for another database, the Aerospike cache's hit ratio is high.\n",
    "- In cases where the hit ratio of either Aerospike or local cache is not high, the local cache advantage is proportionally limited by how large the frequency of access and access time are for the origin database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cache Performance\n",
    "\n",
    "Aerospike, with its speed at scale advantage, is commonly used as a distributed cache server in front of other databases that are limited in speed, throughput, and cost characteristics. \n",
    "\n",
    "We use a simple model to examine how a cache consisting of a local cache and Aerospike database that sits in front of another database."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Model\n",
    "To show the performance gains of a single and dual cache, a simple model is used with two variables for a cache: hit ratio and latency ratio.\n",
    "\n",
    "Note, both ratios are with respect to the data source (or origin) where the cache goes on a miss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Cache\n",
    "For N random accesses to the origin database, the time needed is N * T, where T is the average access time for the origin database.\n",
    "\n",
    "With a hit ratio of H and latency ratio of L:\n",
    "- N\\*H requests are directly served from the cache each with T/L access time. The total access time for cache served requests is  N\\*H\\*T/L.\n",
    "- The remaining N*(1-H) requests are served from the origin in N\\*(1-H)\\*T time.\n",
    "- The total time with a cache is the addition of the above two: N\\*H\\*T/L + N\\*(1-H)\\*T.\n",
    "- The speedup in time and throughput is the ratio of total time without a cache to the total time with a cache. This come to N*T / [N\\*H\\*T/L + N*\\(1-H)\\*T] or 1/(1 - H + H/L).\n",
    "\n",
    "Note, as expected, as H approaches 1 (all requests served from the cache), the speedup approaches L, the latency ratio. Similarly as H approaches 0, the speedup approaches L (no speedup).\n",
    "\n",
    "This equation applies in both single cache scenarios: either a local cache sitting in front of the Aerospike database, or an Aerospike CacheDB sitting in front of another database.\n",
    "\n",
    "The following code implements the speedup function with parameters H and L. These are computed below with various H and L values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\tHR\tSpeedup\n",
      "10\t0.1\t   10%\t*\n",
      "10\t0.3\t   37%\t****\n",
      "10\t0.5\t   82%\t*********\n",
      "10\t0.7\t  170%\t******************\n",
      "10\t0.9\t  426%\t*******************************************\n",
      "100\t0.1\t   11%\t**\n",
      "100\t0.3\t   42%\t*****\n",
      "100\t0.5\t   98%\t**********\n",
      "100\t0.7\t  226%\t***********************\n",
      "100\t0.9\t  817%\t**********************************************************************************\n",
      "1000\t0.1\t   11%\t**\n",
      "1000\t0.3\t   43%\t*****\n",
      "1000\t0.5\t  100%\t**********\n",
      "1000\t0.7\t  233%\t************************\n",
      "1000\t0.9\t  891%\t******************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def single_cache_speedup(hit_ratio, latency_ratio):\n",
    "    return 1.0/(1.0 - hit_ratio + hit_ratio / latency_ratio)\n",
    "\n",
    "hr = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lr = [10, 100, 1000]\n",
    "print('LR', 'HR', 'Speedup', sep='\\t')\n",
    "for l in lr:\n",
    "    for h in hr:\n",
    "        print(l, h, '%5.0f%%'%((single_cache_speedup(h, l)-1)*100), \n",
    "              math.ceil((single_cache_speedup(h, l)-1)*10)*'*', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, a single cache can provide significant performance and throughput boost in the two scenarios:\n",
    "- A local cache to the Aerospike database especially if a high hit ratio can be attained.\n",
    "- Aerospike cache to the backend database because Aerospike provides a large cache size (hence hit ratio) and sub-miilisecond access time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual Cache\n",
    "With a dual cache - a local cache and Aerospike CacheDB - in front of another database, the same equation can be applied for the two levels of caching. The hit-ratio and latency-ratio are with respect to each cache's respective data source. \n",
    "\n",
    "- Level 1 speedup: 1/(1 - H1 + H1/L1)\n",
    "- Level 2 speedup: 1/(1 - H2 + H2/L2)\n",
    "- Combined speedup: 1/(1 - H1 + H1/L1) * 1/(1 - H2 + H2/L2)\n",
    "\n",
    "For simplicity of illustration and to focus on the impact of a local cache in a dual cache setting, we peg the Aerospike CacheDB values to H2=0.8 and L2=100. As Aerospike provides a large cache size with a sub-millisecond range average access time, these numbers are not atypical. \n",
    "\n",
    "The local cache H1 values are varied over (0.1, 0.3, 0.5, 0.7, 0.9) and L1 values over (10, 100, 1000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-12T17:05:32.665229Z",
     "start_time": "2021-01-12T17:05:32.622279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR2=100\tHR2=0.8\tSpeedup with Aerospike Cache Alone: 381%\n",
      "LR1\tHR1\tDual Cache Speedup\n",
      "10\t0.1\t  428%\t*****\n",
      "10\t0.3\t  559%\t******\n",
      "10\t0.5\t  774%\t********\n",
      "10\t0.7\t 1199%\t************\n",
      "10\t0.9\t 2430%\t*************************\n",
      "100\t0.1\t  434%\t*****\n",
      "100\t0.3\t  584%\t******\n",
      "100\t0.5\t  852%\t*********\n",
      "100\t0.7\t 1466%\t***************\n",
      "100\t0.9\t 4311%\t********************************************\n",
      "1000\t0.1\t  434%\t*****\n",
      "1000\t0.3\t  587%\t******\n",
      "1000\t0.5\t  861%\t*********\n",
      "1000\t0.7\t 1499%\t***************\n",
      "1000\t0.9\t 4665%\t***********************************************\n"
     ]
    }
   ],
   "source": [
    "def dual_cache_speedup(hit_ratio_1, latency_ratio_1, hit_ratio_2, latency_ratio_2):\n",
    "    return 1/(1 - hit_ratio_1 + hit_ratio_1 / latency_ratio_1) * 1/(1 - hit_ratio_2 + hit_ratio_2 / latency_ratio_2)\n",
    "\n",
    "h2 = 0.8\n",
    "l2 = 100\n",
    "print('LR2=%3d'%l2, 'HR2=%3.1f'%h2, 'Speedup with Aerospike Cache Alone: %3.0f%%'\n",
    "      %((single_cache_speedup(h2, l2)-1)*100), sep='\\t')\n",
    "\n",
    "hr1 = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "lr1 = [10, 100, 1000]\n",
    "print('LR1', 'HR1', 'Dual Cache Speedup', sep='\\t')\n",
    "for l1 in lr1:\n",
    "    for h1 in hr1:\n",
    "        print(l1, h1, '%5.0f%%'%((dual_cache_speedup(h1, l1, h2, l2)-1)*100), \n",
    "              math.ceil((dual_cache_speedup(h1, l1, h2, l2)-1)*1)*'*', sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen from the numbers above (and should be intuitively clear) that a local cache in a dual cache setting can be very effective especially with large hit ratios. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takeaways\n",
    "The key takeaways are:\n",
    "- A local cache can augment the performance especially when the access pattern provide a higher hit ratio (> 0.5). A local cache can be expensive as it has to be replicated at each client host, but can be effective if high hit ratio is achievable with repeated access to small amounts of data.\n",
    "- Aerospike  provides significant performance and throughput boost over the backend database due to its large cache size (which typically transalates into a higher hit ratio), and a sub-millisecond access time that can be 2 orders of magnitude faster than the backend database. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "Remove data and close the server connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-29T20:49:21.100931Z",
     "start_time": "2020-12-29T20:49:21.095318Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed tutorial data. Connection closed.\n"
     ]
    }
   ],
   "source": [
    "client.truncate(namespace, tutorial_set, 0)\n",
    "# Close the connection to the Aerospike cluster\n",
    "client.close()\n",
    "print('Removed tutorial data. Connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further Exploration and Resources\n",
    "Explore further how Aerospike can be deployed as a cache.\n",
    "- [Blog posts]\n",
    "- [Other resources]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) to run additional Aerospike notebooks. To run a different notebook, download the notebook from the repo to your local machine, and then click on File->Open, and select Upload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
