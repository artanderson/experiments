{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Client Issues: Query and Scan\n",
    "Reproducible cases for potential software bugs and/or documentation issues.\n",
    "<br>\n",
    "This notebook requires Aerospike datbase running on localhost and that python and the Aerospike python client have been installed (`pip install aerospike`). Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) for additional details and the docker container."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensure database is running\n",
    "This notebook requires that Aerospike datbase is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aerospike database is running!\r\n"
     ]
    }
   ],
   "source": [
    "!asd >& /dev/null\n",
    "!pgrep -x asd >/dev/null && echo \"Aerospike database is running!\" || echo \"**Aerospike database is not running!**\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database and populate test data\n",
    "The test data has ten records with user-key \"id1-10\", two bins (fields) \"bin1\" and \"bin2\", in the namespace \"test\" and set \"test_small\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data populated.\n"
     ]
    }
   ],
   "source": [
    "# import the module\n",
    "from __future__ import print_function\n",
    "import aerospike\n",
    "\n",
    "# Configure the client\n",
    "config = {\n",
    "  'hosts': [ ('127.0.0.1', 3000) ],\n",
    "}\n",
    "policy = {'key': aerospike.POLICY_KEY_SEND}   # policy to store the user_key along with the record\n",
    "\n",
    "# Create a client and connect it to the cluster\n",
    "try:\n",
    "  client = aerospike.client(config).connect()\n",
    "except:\n",
    "  import sys\n",
    "  print(\"failed to connect to the cluster with\", config['hosts'])\n",
    "  sys.exit(1)\n",
    "\n",
    "namespace = 'test'\n",
    "small_set = 'test_small'\n",
    "\n",
    "import random\n",
    "random.seed(1)\n",
    "try:\n",
    "    for i in range(10):\n",
    "      # create records in small_set\n",
    "      client.put((namespace, small_set, 'id-'+str(i+1)), \n",
    "                 {'bin1': random.randint(1,100),\n",
    "                  'bin2': random.randint(1,1000) },\n",
    "                 policy=policy)\n",
    "    for i in range(10):\n",
    "      # create records in null set\n",
    "      client.put((namespace, None, 'id-'+str(i+1)), \n",
    "                 {'bin1': random.randint(1,100),\n",
    "                  'bin2': random.randint(1,1000) },\n",
    "                 policy=policy)\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"error: {0}\".format(e), file=sys.stderr)\n",
    "\n",
    "print('Test data populated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create secondary index\n",
    "To use the query API, a secondary index must exist on the query field. We will create an integer secondary index on the \"bin1\" bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secondary index created.\n"
     ]
    }
   ],
   "source": [
    "# Must create an index to query on a bin\n",
    "from aerospike import exception as ex\n",
    "sindex_name = 'test_small_bin1_number_idx'\n",
    "try:\n",
    "    client.index_integer_create(\"test\", small_set, 'bin1', sindex_name)\n",
    "except ex.IndexFoundError:\n",
    "    pass\n",
    "\n",
    "print('Secondary index created.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Query add_ops does not work with update operations in foreground mode (results and foreach). No error is returned.\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.add_ops\n",
    "\n",
    "The API should disallow update operation with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 121}\n",
      "query/add_ops/results returned\n",
      "id-3 {'bin1': 33, 'bin2': 121}\n",
      "current state\n",
      "{'bin1': 33, 'bin2': 121}\n",
      "query/add_ops/foreach returned\n",
      "id-3 {'bin1': 33, 'bin2': 121}\n",
      "final state\n",
      "{'bin1': 33, 'bin2': 121}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from aerospike_helpers.operations import operations as op_helpers\n",
    "from aerospike import predicates as p\n",
    "\n",
    "ops = [\n",
    "    op_helpers.increment(\"bin2\", 1),\n",
    "]\n",
    "\n",
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# Results\n",
    "query = client.query('test', small_set)\n",
    "query.where( p.equals('bin1', 33) )\n",
    "query.add_ops(ops)\n",
    "records = query.results( )\n",
    "print('query/add_ops/results returned')\n",
    "for rec in sorted(records):\n",
    "    print(rec[0][2], rec[2])\n",
    "\n",
    "time.sleep(2)\n",
    "print('current state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "\n",
    "# foreach\n",
    "def print_result(result_tuple):\n",
    "    print(result_tuple[0][2], result_tuple[2])\n",
    "print('query/add_ops/foreach returned')\n",
    "query = client.query('test', small_set)\n",
    "query.where( p.equals('bin1', 33) )\n",
    "query.add_ops(ops)\n",
    "query.foreach(print_result)  \n",
    "\n",
    "time.sleep(2)\n",
    "print('final state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Scan add_ops throws a misleading exception for foreground execution (results and foreach). However the update silently executed in the background mode.\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.add_ops\n",
    "\n",
    "The API should disallow update operation with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 121}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan/add_ops/results error: (-12, 'Max retries exceeded: 0', 'src/main/aerospike/as_partition_tracker.c', 318, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current state\n",
      "{'bin1': 33, 'bin2': 122}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan/add_ops/foreach: error: (-12, 'Max retries exceeded: 0', 'src/main/aerospike/as_partition_tracker.c', 318, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final state\n",
      "{'bin1': 33, 'bin2': 123}\n"
     ]
    }
   ],
   "source": [
    "from aerospike import predexp as predexp\n",
    "preds = [\n",
    "        predexp.integer_bin('bin1'),\n",
    "        predexp.integer_value(33),\n",
    "        predexp.integer_equal()\n",
    "    ]\n",
    "policy = {\n",
    "        'predexp': preds,\n",
    "        'max_retries': 0\n",
    "    }\n",
    "\n",
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# results: exception Max retries exceeded: silently converted into background execution!\n",
    "scan = client.scan('test', small_set)\n",
    "scan.add_ops(ops)\n",
    "try:\n",
    "    records = scan.results(policy=policy) \n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"scan/add_ops/results error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    records = scan.results( )\n",
    "    print('scan/add_ops/results')\n",
    "    for rec in sorted(records):\n",
    "        print(rec[0][2], rec[2]) \n",
    "        \n",
    "time.sleep(2)\n",
    "print('current state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# foreach: exception Max retries exceeded: silently converted into background execution!\n",
    "scan = client.scan('test', small_set)\n",
    "scan.add_ops(ops)\n",
    "try:\n",
    "    scan.foreach(print_result, policy=policy) \n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"scan/add_ops/foreach: error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    print('scan/add_ops/foreach')\n",
    "    \n",
    "time.sleep(2)\n",
    "print('final state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UDF issues**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-- Create a \"udf\" directory and place udf_test.lua file with this content in it. \n",
    "-- udf_test.lua \n",
    "\n",
    "-- read\n",
    "function get_sum(rec, bin1, bin2)\n",
    "    local ret = map()                     -- Initialize the return value (a map)\n",
    "    ret['sum'] = rec[bin1] + rec[bin2]\n",
    "    return ret\n",
    "end\n",
    "\n",
    "-- write\n",
    "function increment(rec, bin_name, value)\n",
    "    rec[bin_name] = rec[bin_name] + value\n",
    "    aerospike:update(rec)\n",
    "end\n",
    "\n",
    "-- read-write\n",
    "function increment_and_get(rec, bin_name, value)\n",
    "    local ret = map()                     -- Initialize the return value (a map)\n",
    "    rec[bin_name] = rec[bin_name] + value\n",
    "    ret[bin_name] = rec[bin_name]\n",
    "    aerospike:update(rec)\n",
    "    return ret\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current udf modules: []\n",
      "current udf modules: [{'name': 'udf_test.lua', 'hash': bytearray(b'1c9810c0e6cc510fc9660bbf0c53581b3663ec52'), 'type': 0, 'content': bytearray(b'')}]\n",
      "-- udf_test.lua \n",
      "\n",
      "-- read\n",
      "function get_sum(rec, bin1, bin2)\n",
      "    local ret = map()                     -- Initialize the return value (a map)\n",
      "    --ret['sum'] = rec[bin1] + rec[bin2]\n",
      "    ret['status'] = 'OK'\n",
      "    ret['userdata'] = rec[bin1] + rec[bin2]\n",
      "    return ret\n",
      "end\n",
      "\n",
      "-- write\n",
      "function increment(rec, binName, value)\n",
      "    rec[binName] = rec[binName] + value\n",
      "    aerospike:update(rec)\n",
      "end\n",
      "\n",
      "-- read-write\n",
      "function increment_and_get(rec, binName, value)\n",
      "    local ret = map()                     -- Initialize the return value (a map)\n",
      "    rec[binName] = rec[binName] + value\n",
      "    ret['status'] = 'OK'\n",
      "    ret['userdata'] = rec[binName]\n",
      "    aerospike:update(rec)\n",
      "    return ret\n",
      "end\n"
     ]
    }
   ],
   "source": [
    "#client.close()\n",
    "udf_file = 'udf_test.lua'\n",
    "udf_path = './udf'\n",
    "config = {\n",
    "    'hosts': [ ('127.0.0.1', 3000)],\n",
    "    'lua': { 'user_path': udf_path} # needed for only stream/aggregate processing?\n",
    "}\n",
    "client = aerospike.client(config).connect()\n",
    "client.udf_remove(udf_file)\n",
    "print('current udf modules:', client.udf_list())\n",
    "client.udf_put(udf_path + '/' + udf_file)\n",
    "print('current udf modules:', client.udf_list())\n",
    "print(client.udf_get(udf_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Record UDF (update) operations work with query in background execution. Doc seems to suggest only stream UDF functions work with query.\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.apply\n",
    "\n",
    "The documentation should reflect valid and allowed use of record UDFs with a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 123}\n",
      "query/record_udf update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 133}\n"
     ]
    }
   ],
   "source": [
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "q = client.query('test', small_set)\n",
    "q.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "q.where( p.equals('bin1', 33) )\n",
    "job_id = q.execute_background()\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_QUERY)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('query/record_udf update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Query apply (udf op) does not work for read operations with results and foreach. \n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.apply\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.results\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.foreach\n",
    "\n",
    "The API should disallow apply operation with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan/record-udf read/results: error: (100, 'UDF: Execution Error 1', 'src/main/aerospike/aerospike_query.c', 1008, False)\n"
     ]
    }
   ],
   "source": [
    "q = client.query('test', small_set)\n",
    "q.where( p.equals('bin1', 33) )\n",
    "q.apply('udf_test', 'get_sum', [ 'bin1', 'bin2' ])\n",
    "try:\n",
    "    records = q.results()\n",
    "except Exception as e:\n",
    "    import sys\n",
    "    print(\"scan/record-udf read/results: error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    print('scan/record-udf read/results')\n",
    "    for rec in sorted(records):\n",
    "        print(rec[0][2], rec[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Scan apply (udf op) does not work for read operations in foreground mode (results and foreach). A cryptic error is returned.\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.apply\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.results\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.foreach\n",
    "\n",
    "The API should disallow apply with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan/record-udf read/results: error: (-12, 'Max retries exceeded: 0', 'src/main/aerospike/as_partition_tracker.c', 318, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "{'bin1': 33, 'bin2': 133}\n"
     ]
    }
   ],
   "source": [
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "scan = client.scan('test', small_set)\n",
    "scan.apply('udf_test', 'get_sum', [ 'bin1', 'bin2' ])\n",
    "try:\n",
    "    records = scan.results(policy)\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"scan/record-udf read/results: error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    print('scan/record-udf read/results')\n",
    "    for rec in sorted(records):\n",
    "        print(rec[0][2], rec[2])\n",
    "time.sleep(2)\n",
    "print('state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Query apply (udf op) does not work for update operations in foreground mode (results and foreach).\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.apply\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.results\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.foreach\n",
    "\n",
    "The API should disallow apply operation with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "query/record-udf update/results: error: (100, 'UDF: Execution Error 1', 'src/main/aerospike/aerospike_query.c', 1008, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "{'bin1': 33, 'bin2': 133}\n"
     ]
    }
   ],
   "source": [
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# try if record udfs work with query for update/results\n",
    "# -> attempt to perform on a nil value field?\n",
    "q = client.query('test', small_set)\n",
    "q.where( p.equals('bin1', 33) )\n",
    "q.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "try:\n",
    "    records = q.results()\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"query/record-udf update/results: error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    print('query/record-udf update/results')\n",
    "    for rec in sorted(records):\n",
    "        print(rec[0][2], rec[2])\n",
    "time.sleep(1)\n",
    "print('state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: Scan apply (udf op) returns a crypic error for update operations in foreground mode (results and foreach). However the update succeeds in the background.\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.apply\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.results\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.foreach\n",
    "\n",
    "The API should disallow update operation with results and foreach. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 133}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan/record-udf read/results: error: (-12, 'Max retries exceeded: 0', 'src/main/aerospike/as_partition_tracker.c', 318, False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state\n",
      "{'bin1': 33, 'bin2': 143}\n"
     ]
    }
   ],
   "source": [
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# results will return immediately, but the operation will work like execute_background\n",
    "# foreach also should work similarly\n",
    "scan = client.scan('test', small_set)\n",
    "scan.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "try:\n",
    "    records = scan.results(policy)\n",
    "except Exception as e:\n",
    "  import sys\n",
    "  print(\"scan/record-udf read/results: error: {0}\".format(e), file=sys.stderr)\n",
    "else:\n",
    "    print('scan/record-udf update/results')\n",
    "    for rec in sorted(records):\n",
    "        print(rec[0][2], rec[2])\n",
    "time.sleep(2)\n",
    "print('state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: If both add-ops and apply are used in a scan to perform updates in background mode, only apply operations work. Updates in add-ops are silently ignored.\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.apply\n",
    "https://www.aerospike.com/apidocs/python/scan.html#aerospike.Scan.add_ops\n",
    "\n",
    "The API should disallow combined apply and add_ops. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 143}\n",
      "after scan/op update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 144}\n",
      "after scan/record_udf update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 154}\n",
      "after scan/record_udf+op combo update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 164}\n"
     ]
    }
   ],
   "source": [
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "ops = [\n",
    "    op_helpers.increment(\"bin2\", 1),\n",
    "]\n",
    "# First scan\n",
    "# Scan - only add-op works\n",
    "scan = client.scan('test', small_set)\n",
    "scan.add_ops(ops)\n",
    "job_id = scan.execute_background(policy)\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_SCAN)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after scan/op update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)\n",
    "\n",
    "# Scan - only apply works\n",
    "scan = client.scan('test', small_set)\n",
    "scan.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "job_id = scan.execute_background(policy)\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_SCAN)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after scan/record_udf update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)\n",
    "\n",
    "# Scan - if both add-op and apply are issued, add-op is silently ignored\n",
    "scan = client.scan('test', small_set)\n",
    "scan.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "scan.add_ops(ops)\n",
    "job_id = scan.execute_background(policy)\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_SCAN)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after scan/record_udf+op combo update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Issue: If both add-ops and apply are used in a query to perform updates in background mode, only apply operations work. Updates in add-ops are silently ignored. \n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.apply\n",
    "https://www.aerospike.com/apidocs/python/query.html#aerospike.Query.add_ops\n",
    "\n",
    "The API should disallow combined use of add_ops and apply. Documentation should warn users against such use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state\n",
      "{'bin1': 33, 'bin2': 164}\n",
      "after query/op update update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 165}\n",
      "after query/record_udf update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 175}\n",
      "after query/record_udf+op combo update/beckground\n",
      "record bins: {'bin1': 33, 'bin2': 185}\n"
     ]
    }
   ],
   "source": [
    "# now query\n",
    "print('initial state')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print(bins)\n",
    "\n",
    "# only add-ops update works\n",
    "q = client.query('test', small_set)\n",
    "q.where( p.equals('bin1', 33) )\n",
    "q.add_ops(ops)\n",
    "job_id = q.execute_background()\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_QUERY)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after query/op update update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)\n",
    "\n",
    "# only apply update works\n",
    "q = client.query('test', small_set)\n",
    "q.where( p.equals('bin1', 33) )\n",
    "q.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "job_id = q.execute_background()\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_QUERY)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after query/record_udf update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)\n",
    "\n",
    "# in combined add-ops+apply, add-ops update is silently ignored\n",
    "q = client.query('test', small_set)\n",
    "q.where( p.equals('bin1', 33) )\n",
    "q.apply('udf_test', 'increment', [ 'bin2', 10 ])\n",
    "q.add_ops(ops)\n",
    "job_id = q.execute_background()\n",
    "while True:\n",
    "    time.sleep(0.25)\n",
    "    response = client.job_info(job_id, aerospike.JOB_QUERY)\n",
    "    if response['status'] == aerospike.JOB_STATUS_COMPLETED:\n",
    "        break\n",
    "print('after query/record_udf+op combo update/beckground')\n",
    "key, _, bins = client.get(('test',small_set,'id-3'))\n",
    "print('record bins:', bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection closed.\n"
     ]
    }
   ],
   "source": [
    "# Close the connection to the Aerospike cluster\n",
    "client.close()\n",
    "print('Connection closed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Visit [Aerospike notebooks repo](https://github.com/aerospike-examples/interactive-notebooks) to run additional Aerospike notebooks. To run a different notebook, download the notebook from the repo to your local machine, and then click on File->Open, and select Upload."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
